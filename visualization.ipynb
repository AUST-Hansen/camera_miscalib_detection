{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for TF Session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided ReLU for guided backpropogation\n",
    "\n",
    "Source: https://github.com/adityac94/Grad_CAM_plus_plus/blob/master/misc/GuideReLU.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace vanila relu to guided relu to get guided backpropagation.\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "import tensorflow as tf\n",
    "\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.where(0. < grad, gen_nn_ops._relu_grad(grad, op.outputs[0]), tf.zeros_like(grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KITTI Index File: /home/mayankm/my_projects/data/kitti/KITTI_index.csv\n",
      "Model Path: /media/storage/my_projects/semantics_miscalib_PLR/plr_miscalib_detection/models/miscalib-model-cam03\n"
     ]
    }
   ],
   "source": [
    "index = os.path.abspath('/home/mayankm/my_projects/data/kitti/KITTI_index.csv')\n",
    "test_selector = '2011_09_30'\n",
    "n_test_samples = 1\n",
    "batch_size = 1\n",
    "buffer_size = 32\n",
    "model_path = os.path.abspath('models/miscalib-model-cam03/')\n",
    "model_name = 'model-22-46483'\n",
    "verbosity = 1\n",
    "njobs = 9\n",
    "\n",
    "print('KITTI Index File: ' + index)\n",
    "print('Model Path: ' + model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1230 images found in 2 folders grouped in 2 groups from index file /home/mayankm/my_projects/data/kitti/KITTI_index.csv, when applying selector '2011_09_30'.\n",
      "The samplers were initialized in 30.84 sec.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset.\n",
    "from dataset import Dataset\n",
    "\n",
    "dataset_test = Dataset(index, selector=test_selector, internal_shuffle=True,\n",
    "                       num_of_samples=n_test_samples, n_jobs=njobs, verbose=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with 1 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayankm/.virtualenvs/plr_pytorch/lib/python3.5/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator StandardScaler from version 0.20.3 when using version 0.21.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "# Load previous scaler\n",
    "scaler_path = os.path.join(model_path, 'scaler.p')\n",
    "scaler = pickle.load(open(scaler_path, 'rb'), encoding='latin1')\n",
    "dataset_test.set_scaler(scaler)\n",
    "\n",
    "print('Test with %d images' % (dataset_test.n_samples))\n",
    "\n",
    "ids_test = np.arange(dataset_test.n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling generator buffer. Done\n"
     ]
    }
   ],
   "source": [
    "# Create batch generators for the test sets.\n",
    "from generator import Generator\n",
    "\n",
    "gen_test = Generator(dataset_test, ids_test, batch_size=batch_size, shuffle=True,\n",
    "                     buffer_size=buffer_size, verbose=verbosity)\n",
    "\n",
    "# Define tf model.\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Set tensorflow to only log errors\n",
    "if verbosity == 0:\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model metafile:  /media/storage/my_projects/semantics_miscalib_PLR/plr_miscalib_detection/models/miscalib-model-cam03/model-22-46483.meta\n",
      "Input shape:  (512, 1392, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load previous metegraph\n",
    "meta_file = os.path.join(model_path, model_name + '.meta')\n",
    "print(\"Loading model metafile: \", meta_file)\n",
    "saver = tf.train.import_meta_graph(meta_file)\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Check input shape\n",
    "print(\"Input shape: \", dataset_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve TF Tensors for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_image:0\", shape=(?, 512, 1392, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Inputs.\n",
    "input_image_tf = graph.get_tensor_by_name('input_image:0')\n",
    "y_true_tf = graph.get_tensor_by_name('y_true:0')\n",
    "\n",
    "training_tf = graph.get_tensor_by_name('training:0')\n",
    "\n",
    "loss_tf = graph.get_tensor_by_name('loss_mse:0')\n",
    "error_tf = graph.get_tensor_by_name('error_mae:0')\n",
    "\n",
    "# Global step for logging.\n",
    "global_step = 0\n",
    "\n",
    "print(input_image_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of GradCAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get the names of all the tensors in the graph\n",
    "# [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_conv_layer = graph.get_tensor_by_name('conv_block_7/conv2/Relu:0')\n",
    "output_neuron = graph.get_tensor_by_name('Squeeze:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def compute_gradcam_plusplus(conv_output, conv_first_grad, conv_second_grad, conv_third_grad, shape=(512, 1392)):\n",
    "    \"\"\" Computes the GradCAM++\n",
    "    \"\"\"\n",
    "    global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n",
    "\n",
    "    alpha_num = conv_second_grad[0]\n",
    "    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num/alpha_denom\n",
    "\n",
    "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "    #normalizing the alphas\n",
    "    \"\"\"\t\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas, axis=0),axis=0)\n",
    "\n",
    "    alphas /= alpha_normalization_constant.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    \"\"\"\n",
    "\n",
    "    alphas_thresholding = np.where(weights, alphas, 0.0)\n",
    "\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas_thresholding, axis=0),axis=0)\n",
    "    alpha_normalization_constant_processed = np.where(alpha_normalization_constant != 0.0, alpha_normalization_constant, np.ones(alpha_normalization_constant.shape))\n",
    "\n",
    "\n",
    "    alphas /= alpha_normalization_constant_processed.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "    deep_linearization_weights = np.sum((weights*alphas).reshape((-1,conv_first_grad[0].shape[2])),axis=0)\n",
    "    \n",
    "    # print deep_linearization_weights\n",
    "    grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n",
    "\n",
    "    # Passing through ReLU\n",
    "    cam = np.maximum(grad_CAM_map, 0)\n",
    "    cam = cam / np.max(cam) # scale 0 to 1.0   \n",
    "\n",
    "    cam = resize(cam, shape)\n",
    "    # Passing through ReLU\n",
    "    cam = np.maximum(grad_CAM_map, 0)\n",
    "    cam = cam / np.max(cam) # scale 0 to 1.0    \n",
    "    cam = resize(cam, shape)\n",
    "    \n",
    "    # return the cam array\n",
    "    return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def visualize(img, cam):\n",
    "  \n",
    "    fig, ax = plt.subplots(nrows=2,ncols=1)\n",
    "\n",
    "#     plt.subplot(311)\n",
    "#     plt.axis(\"off\")\n",
    "#     imgplot = plt.imshow(img)\n",
    "    \n",
    "#     gb_viz = np.dstack((\n",
    "#                 gb_viz[:, :, 2],\n",
    "#                 gb_viz[:, :, 1],\n",
    "#                 gb_viz[:, :, 0],\n",
    "#                 ))\n",
    "\n",
    "#     gb_viz -= np.min(gb_viz)\n",
    "#     gb_viz /= gb_viz.max()\n",
    "    \n",
    "#     gd_img = gb_viz*np.minimum(0.25,cam).reshape(512, 1392,1)\n",
    "#     x = gd_img\n",
    "#     x = np.squeeze(x)\n",
    "    \n",
    "#     #normalize tensor\n",
    "#     x -= x.mean()\n",
    "#     x /= (x.std() + 1e-5)\n",
    "#     x *= 0.1\n",
    "\n",
    "#     # clip to [0, 1]\n",
    "#     x += 0.5\n",
    "#     x = np.clip(x, 0, 1)\n",
    "\n",
    "#     # convert to RGB array\n",
    "#     x *= 255\n",
    "   \n",
    "#     x = np.clip(x, 0, 255).astype('uint8')\n",
    "\n",
    "#     plt.axis(\"off\")\n",
    "#     imgplot = plt.imshow(x, vmin = 0, vmax = 20)\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.axis(\"off\")\n",
    "    cam = (cam*-1.0) + 1.0\n",
    "    cam_heatmap = np.array(cv2.applyColorMap(np.uint8(255*cam), cv2.COLORMAP_JET))\n",
    "    imgplot = plt.imshow(cam_heatmap)\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.axis(\"off\")\n",
    "    cam_heatmap = cam_heatmap/255.0\n",
    "    fin = (img * 0.7) + (cam_heatmap*0.3)\n",
    "    imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    with graph.gradient_override_map({'Relu': 'GuidedRelu'}):\n",
    "        # get the output neuron corresponding to the class of interest (label_id)\n",
    "        cost = loss_tf\n",
    "        \n",
    "        # get last convolutional layer gradients for generating gradCAM++ visualization\n",
    "        target_conv_layer_grad = tf.gradients(cost, target_conv_layer)[0]\n",
    "        \n",
    "        # first_derivative\n",
    "        first_derivative = tf.exp(cost) * target_conv_layer_grad\n",
    "        # second_derivative\n",
    "        second_derivative = tf.exp(cost) * target_conv_layer_grad * target_conv_layer_grad \n",
    "        # triple_derivative\n",
    "        triple_derivative = tf.exp(cost) * target_conv_layer_grad * target_conv_layer_grad * target_conv_layer_grad\n",
    "        \n",
    "        # get gradients with respect to input for guided backprop\n",
    "        gb_grad = tf.gradients(cost, input_image_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/storage/my_projects/semantics_miscalib_PLR/plr_miscalib_detection/models/miscalib-model-cam03/model-22-46483\n",
      "step     1 Test: loss_mse: 0.0025 err_mae 0.0503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    # Initialize tf variables.\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    # load the model\n",
    "    model_file = os.path.join(model_path, model_name)\n",
    "    saver.restore(sess, model_file)\n",
    "\n",
    "    # Sequence of train and validation batches.\n",
    "    test_step = 0\n",
    "    console_output_size = 0\n",
    "    \n",
    "    for b in range(gen_test.n_batches):\n",
    "        images_batch, labels_batch = gen_test.next()\n",
    "\n",
    "        # Calculate validation loss.\n",
    "        batch_loss, batch_error = sess.run(\n",
    "            [loss_tf, error_tf],\n",
    "            feed_dict={input_image_tf: images_batch,\n",
    "                       y_true_tf: labels_batch})\n",
    "\n",
    "        # Print results.\n",
    "        test_step += 1\n",
    "        sys.stdout.write('\\b' * console_output_size)\n",
    "\n",
    "        console_output = 'step %5d ' % test_step\n",
    "        console_output += 'Test: loss_mse: %.4f err_mae %.4f' % (\n",
    "            batch_loss, batch_error)\n",
    "\n",
    "        console_output_size = len(console_output)\n",
    "\n",
    "        sys.stdout.write(console_output)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        # Compute the GradCAM gradients\n",
    "        conv_output, conv_first_grad, conv_second_grad, conv_third_grad = sess.run(\n",
    "            [target_conv_layer, first_derivative, second_derivative, triple_derivative], \n",
    "            feed_dict={input_image_tf: images_batch,\n",
    "                       y_true_tf: labels_batch})\n",
    "\n",
    "        # Compute the mask image\n",
    "        cam = compute_gradcam_plusplus(conv_output, conv_first_grad, conv_second_grad, conv_third_grad)\n",
    "\n",
    "        # Compute the guided backprop \n",
    "        gb_grad_value = sess.run(\n",
    "            gb_grad, \n",
    "            feed_dict={input_image_tf: images_batch,\n",
    "                       y_true_tf: labels_batch})\n",
    "\n",
    "        visualize(images_batch[0], cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /media/storage/my_projects/semantics_miscalib_PLR/plr_miscalib_detection/models/miscalib-model-cam03/model-22-46483\n",
      "step     1 Test: loss_mse: 0.0005 err_mae 0.0234\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    # Initialize tf variables.\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    model_file = os.path.join(model_path, model_name)\n",
    "    saver.restore(sess, model_file)\n",
    "    \n",
    "    # Sequence of train and validation batches.\n",
    "    test_loss = 0\n",
    "    test_error = 0\n",
    "    test_step = 0\n",
    "\n",
    "    console_output_size = 0\n",
    "    for b in range(gen_test.n_batches):\n",
    "        images_batch, labels_batch = gen_test.next()\n",
    "\n",
    "        # Calculate validation loss.\n",
    "        batch_loss, batch_error = sess.run(\n",
    "            [loss_tf, error_tf],\n",
    "            feed_dict={input_image_tf: images_batch,\n",
    "                       y_true_tf: labels_batch})\n",
    "        test_loss += batch_loss\n",
    "        test_error += batch_error\n",
    "        test_step += 1\n",
    "\n",
    "        # Print results.\n",
    "        sys.stdout.write('\\b' * console_output_size)\n",
    "\n",
    "        console_output = 'step %5d ' % test_step\n",
    "        console_output += 'Test: loss_mse: %.4f err_mae %.4f' % (\n",
    "            test_loss / test_step, test_error / test_step)\n",
    "\n",
    "        console_output_size = len(console_output)\n",
    "\n",
    "        sys.stdout.write(console_output)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plr_pytorch",
   "language": "python",
   "name": "plr_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
